{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addbff6b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#卷积神经网络\" data-toc-modified-id=\"卷积神经网络-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>卷积神经网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#CBAPD部分\" data-toc-modified-id=\"CBAPD部分-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>CBAPD部分</a></span></li><li><span><a href=\"#cifar数据实例\" data-toc-modified-id=\"cifar数据实例-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>cifar数据实例</a></span></li></ul></li><li><span><a href=\"#循环神经网络\" data-toc-modified-id=\"循环神经网络-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>循环神经网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#循环神经网络\" data-toc-modified-id=\"循环神经网络-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>循环神经网络</a></span></li><li><span><a href=\"#字母预测\" data-toc-modified-id=\"字母预测-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>字母预测</a></span><ul class=\"toc-item\"><li><span><a href=\"#one_hot实现字母预测\" data-toc-modified-id=\"one_hot实现字母预测-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>one_hot实现字母预测</a></span></li><li><span><a href=\"#独热编码和embedding：\" data-toc-modified-id=\"独热编码和embedding：-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>独热编码和embedding：</a></span></li></ul></li><li><span><a href=\"#股票预测\" data-toc-modified-id=\"股票预测-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>股票预测</a></span><ul class=\"toc-item\"><li><span><a href=\"#RNN股票预测\" data-toc-modified-id=\"RNN股票预测-7.3.1\"><span class=\"toc-item-num\">7.3.1&nbsp;&nbsp;</span>RNN股票预测</a></span></li><li><span><a href=\"#LSTM预测股票\" data-toc-modified-id=\"LSTM预测股票-7.3.2\"><span class=\"toc-item-num\">7.3.2&nbsp;&nbsp;</span>LSTM预测股票</a></span></li><li><span><a href=\"#GRU预测股票\" data-toc-modified-id=\"GRU预测股票-7.3.3\"><span class=\"toc-item-num\">7.3.3&nbsp;&nbsp;</span>GRU预测股票</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf794ae1",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "     全连接网络NN：每个神经元都与前后相邻层的每一个神经元有链接，输入时特征，输出时预测结果。\n",
    "     参数个数：sum(前层*后层+后层)每一层。\n",
    "     实践证明，全连接网络对识别和预测都有很好的效果，但是对于像三通道图像数据，就会生成大量待估参数。\n",
    "\n",
    "    卷积计算式是一种有效提取图像特征的方法，\n",
    "    一般会用一个正方形的卷积核，按照指定步长，在输入特征上滑动，遍历输入特征图中的每个像素点，每一个步长，卷积核会与输入特征图出现重合区域，重合区域对应元素相乘，求和再加上偏置项得到输出特征的一个像素点\n",
    "\n",
    "\n",
    "    本讲目标：***卷积就是特征提取器，CBAPD***\n",
    "    卷积计算过程  \n",
    "    感受野\n",
    "    全零填充padding\n",
    "    tf描述卷积计算层\n",
    "    批标准化 batch normalization ,BN\n",
    "    池化 pooling\n",
    "    舍弃 dropout\n",
    "    卷积神经网络\n",
    "    cifar10数据集\n",
    "    搭建实例\n",
    "    实现LeNet,AlexNet,VGGNet,InceptionNet,ResNet 5个经典神经网络\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608438e",
   "metadata": {},
   "source": [
    "## CBAPD部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 感受野receptive filed:卷积神经网络各输出特征图中一个像素点，在原始输入特片上映射区域的大小\n",
    "# 两层3*3的卷积核和一层5*5的卷积核的感受野相同，但是带训练参数前者更小，计算量更小，所以，一般选择前者\n",
    "\n",
    "# 全零填充 padding='SAME' or 'VALID'\n",
    "#     SAME全零填充，保证输出特征图大小和原来一样，入长/步长，向上取整\n",
    "#     VALID非全零填充，(入长-核长+1)/步长，向上取整\n",
    " \n",
    "tf描述卷积计算过程：\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters=卷积核个数，\n",
    "    kernal_size = 卷积和尺寸，正方形写核长整数，或者(核高，核宽)\n",
    "    strides = 滑动步长，默认1，\n",
    "    paddings = 'same' or 'valid',\n",
    "    activation = 'relu' or 'softmax' or 'sigmoid' or 'tanh',若有BN,此处不写\n",
    "    input_shape = (高，宽，通道数)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cac368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批标准化：随着网络层数增加，特征数据会出现偏离0均值的情况，在卷积操作和激活操作之间进行\n",
    "# 对每批进入神经网络的数据，每个输出特征图按照本图的均值和标准差进行批标准化，\n",
    "# 该操作将本来偏移零均值的数据拉回零均值附近，BN操作可以使得进入激活函数的数据分布在激活函数线性区，数据微小的变化更明显的提现到激活函数的输出，提升了激活函数对输入数据的敏感性。\n",
    "# 但是这种简单的数据标准化也会使得数据集中在激活函数的线性区域中，使得激活函数丧失了非线性的特性。\n",
    "# 因此在BN操作中为每个卷积核引入两个可以训练的参数gama缩放因子和beta偏移因子，优化了特征数据分布的宽窄和偏移量，可在反向传播时一起被训练优化，\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(filters=6,kernal_size=5,padding='same'),  #卷积层\n",
    "    BatchNormalization(),  #BN层\n",
    "    Activation('rule'),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2,padding='same'),\n",
    "    Dropout=(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 池化：用于减少特征数量，主要方法有最大池化和均值池化，最大池化提取图片纹理，均值池化保留背景特征\n",
    "# tf 描述池化：\n",
    "tf.keras.layers.MaxPool2D(\n",
    "    pool_size=池化核尺寸，正方形写核长整数，或者（核高h,核宽w）\n",
    "    strides=池化步长，步长整数，或者（纵步h,横步w）默认pool_size,\n",
    "    padding='valid' or 'same'\n",
    ")\n",
    "\n",
    "tf.keras.layers.AveragePool2D(\n",
    "    pool_size=池化核尺寸，正方形写核长整数，或者（核高h,核宽w）\n",
    "    strides=池化步长，步长整数，或者（纵步h,横步w）默认pool_size,\n",
    "    padding='valid' or 'same'\n",
    ")\n",
    "# 实例如上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a586a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 舍弃：神经网络训练时为了缓解过拟合，将一部分神经元按照一定概率舍弃，使用时，恢复舍弃的神经元\n",
    "# 实例如上dropout=(0.2)\n",
    "\n",
    "# 卷积神经网络：借助卷积核提取特征，送入全连接网络。\n",
    "# 主要模块：卷积C》批标准化B》激活函数A》池化P》舍弃D》全链接FC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d76b4",
   "metadata": {},
   "source": [
    "## cifar数据实例\n",
    "\n",
    "    5万张32*32像素点的十分类彩色图片和标签，训练集\n",
    "    1万张32*32像素点的十分类图片和标签，测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6562427",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train[0]:\n",
      " [[[0.23137255 0.24313725 0.24705882]\n",
      "  [0.16862745 0.18039216 0.17647059]\n",
      "  [0.19607843 0.18823529 0.16862745]\n",
      "  ...\n",
      "  [0.61960784 0.51764706 0.42352941]\n",
      "  [0.59607843 0.49019608 0.4       ]\n",
      "  [0.58039216 0.48627451 0.40392157]]\n",
      "\n",
      " [[0.0627451  0.07843137 0.07843137]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.07058824 0.03137255 0.        ]\n",
      "  ...\n",
      "  [0.48235294 0.34509804 0.21568627]\n",
      "  [0.46666667 0.3254902  0.19607843]\n",
      "  [0.47843137 0.34117647 0.22352941]]\n",
      "\n",
      " [[0.09803922 0.09411765 0.08235294]\n",
      "  [0.0627451  0.02745098 0.        ]\n",
      "  [0.19215686 0.10588235 0.03137255]\n",
      "  ...\n",
      "  [0.4627451  0.32941176 0.19607843]\n",
      "  [0.47058824 0.32941176 0.19607843]\n",
      "  [0.42745098 0.28627451 0.16470588]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.81568627 0.66666667 0.37647059]\n",
      "  [0.78823529 0.6        0.13333333]\n",
      "  [0.77647059 0.63137255 0.10196078]\n",
      "  ...\n",
      "  [0.62745098 0.52156863 0.2745098 ]\n",
      "  [0.21960784 0.12156863 0.02745098]\n",
      "  [0.20784314 0.13333333 0.07843137]]\n",
      "\n",
      " [[0.70588235 0.54509804 0.37647059]\n",
      "  [0.67843137 0.48235294 0.16470588]\n",
      "  [0.72941176 0.56470588 0.11764706]\n",
      "  ...\n",
      "  [0.72156863 0.58039216 0.36862745]\n",
      "  [0.38039216 0.24313725 0.13333333]\n",
      "  [0.3254902  0.20784314 0.13333333]]\n",
      "\n",
      " [[0.69411765 0.56470588 0.45490196]\n",
      "  [0.65882353 0.50588235 0.36862745]\n",
      "  [0.70196078 0.55686275 0.34117647]\n",
      "  ...\n",
      "  [0.84705882 0.72156863 0.54901961]\n",
      "  [0.59215686 0.4627451  0.32941176]\n",
      "  [0.48235294 0.36078431 0.28235294]]]\n",
      "y_train[0]:\n",
      " [6]\n",
      "x_train.shape:\n",
      " (50000, 32, 32, 3)\n",
      "y_train.shape:\n",
      " (50000, 1)\n",
      "x_test.shape:\n",
      " (10000, 32, 32, 3)\n",
      "y_test.shape:\n",
      " (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 导入数据集，十分类分别是飞机汽车鸟猫鹿狗青蛙马船和卡车\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "cifar10=tf.keras.datasets.cifar10\n",
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "x_train,x_test = x_train/255.0,x_test/255.0\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "print('x_train[0]:\\n',x_train[0])\n",
    "print('y_train[0]:\\n',y_train[0])\n",
    "print('x_train.shape:\\n',x_train.shape)\n",
    "print('y_train.shape:\\n',y_train.shape)\n",
    "print('x_test.shape:\\n',x_test.shape)\n",
    "print('y_test.shape:\\n',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d3a903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-573214e3fd2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m ])\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# class搭建网络\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMaxPool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFaltten\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mBashline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf'"
     ]
    }
   ],
   "source": [
    "# 搭建一层卷积两层全连接网络\n",
    "#sequencial搭建结构\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6,kernel_size=5,strides=2,padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2,padding='same'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "### class搭建网络\n",
    "# from tensorflow.keras.layers import Conv2D,BatchNormalization,Activation,MaxPool,Faltten,Dense,Dropout\n",
    "# from tf.keras import Model\n",
    "# class Bashline(Model):\n",
    "#     def __init__(self,Model):\n",
    "#         super(Bashline,self).__init__()\n",
    "#         self.c1 = Conv2D(filters=6,kernel_size=5,strides=2,padding='same')\n",
    "#         self.b1 = BatchNormalization()\n",
    "#         self.a1 = Activation('relu')\n",
    "#         self.p1 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "#         self.d1 = Dropout(0.2)\n",
    "#         self.flatten = Flatten()\n",
    "#         self.f1 = Dense(128,activation='relu')\n",
    "#         self.d2 = Dropout(0.2)\n",
    "#         self.f2 = Dense(10,activation='softmax')\n",
    "#     def call(self,x):\n",
    "#         x = self.c1(x)\n",
    "#         x = self.b1(x)\n",
    "#         x = self.a1(x)\n",
    "#         x = self.p1(x)\n",
    "#         x = self.d1(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.f1(x)\n",
    "#         x = self.d2(x)\n",
    "#         y = self.f2(x)\n",
    "#         return y\n",
    "# model = Bashline()\n",
    "            \n",
    "    \n",
    "#配置参数\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "# 断点续训\n",
    "checkpoint_save_path = 'D:/tensorflow笔记/class5/checkpoint/Baseline.ckpt'  #ckpt文件会生成对应的index文件\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-----------load model----------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_save_path,\n",
    "    save_weights_only = True,\n",
    "    save_best_only= True)\n",
    "history=model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_test,y_test),validation_freq=1,\n",
    "         callbacks=[cp_callback])\n",
    "model.summary()\n",
    "\n",
    "# 保存参数\n",
    "file=open('D:/tensorflow笔记/class5/weights.txt','w')\n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name)+'\\n')\n",
    "    file.write(str(v.shape)+'\\n')\n",
    "    file.write(str(v.numpy())+'\\n')\n",
    "file.close()\n",
    "\n",
    "# 显示acc和loss曲线\n",
    "acc = history.history['sparse_categorical_accuracy']\n",
    "val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc,label='Training Accuracy')\n",
    "plt.plot(val_acc,label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss,label='Training Loss')\n",
    "plt.plot(val_loss,label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3848f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经典神经网络LeNet(1998) > AlexNet(2012) > VGGNet(2014) > InceptionNet(2014) > ResNet(2015)\n",
    "# LeNet:通过共享卷积核减少参数，共有5层，两层卷积，两层全连接（一般只把卷积层和全连接层看成一层，其他的是层中附属）\n",
    "from tensorflow.keras import Model\n",
    "class LeNet5(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet5,self).__init__()\n",
    "        self.c1 = Conv2D(filters=6,kernel_size=(5,5),activation='sigmoid')\n",
    "        self.p1 = MaxPool2D(pool_size=(2,2),strides=2)\n",
    "        self.c2 = Conv2D(filters=16,kernel_size=(5,5),activation='sigmoid')\n",
    "        self.p2 = MaxPool2D(pool_size=(2,2),strides=2)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.f1 = Dense(120,activation='sigmoid')\n",
    "        self.f2 = Dense(84,activation='sigmoid')\n",
    "        self.f3 = Dense(10,activation='softmax')\n",
    "    def call(self):\n",
    "        x = self.c1(x)\n",
    "        x = self.p1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.p2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.f1(x)\n",
    "        x = self.f2(x)\n",
    "        y = self.f3(x)\n",
    "        return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a93220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet共有8层:5层卷积，3层全连接\n",
    "# 使用relu激活函数，提升训练速度，使用dropout缓解过拟合\n",
    "class AlexNet8(Model):\n",
    "    def __ini__(self):\n",
    "        super(AlexNet8,self).__init__()\n",
    "        self.c1 = Conv2D(filters=96,kernel_size=(3,3))\n",
    "        self.b1 = BatchNormalization()\n",
    "        self.a1 = Activation('relu')\n",
    "        self.p1 = MaxPool2D(pool_size=(3,3),strides=2)\n",
    "        \n",
    "        self.c2 = Conv2D(filters=256,kernel_size=(3,3))\n",
    "        self.b2 = BatchNormalization()\n",
    "        self.a2 = Activation('relu')\n",
    "        self.p2 = MaxPool2D(pool_size=(3,3),strides=2)\n",
    "        \n",
    "        self.c3 = Conv2D(filters=384,kernel_size=(3,3),padding='same')\n",
    "        self.a3 = Activation('relu')\n",
    "        \n",
    "        self.c4 = Conv2D(filter=384,kernel_size=(3,3),padding='same')\n",
    "        self.a4 = Activation('relu')\n",
    "        \n",
    "        self.c5 = Conv2D(filter=256,kernel_size=(3,3),padding='same')\n",
    "        self.a5 = Activation('relu')\n",
    "        self.p5 = MaxPool2D(pool_size=(3,3),strides=2)\n",
    "        \n",
    "        self.flatten = Faltten()\n",
    "        self.f6 = Dense(filters=2048,activation='relu')\n",
    "        self.d6 = Dropout(0.5)\n",
    "        \n",
    "        self.f7 = Dense(filters=2048,activation='relu')\n",
    "        self.d7 = Dropout(0.5)\n",
    "        \n",
    "        self.f8 = Dense(filters=10,activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGNet：使用小尺寸卷积核，在减少参数的同时，提高了识别的准确率\n",
    "# 该网络结构规整，适合并行加速，非常适合硬件加速，13层卷积，3层全连接\n",
    "# 越靠后卷积核数量越多，因为，特征图尺寸越小，\n",
    "# 通过增加卷积核的个数，增加了特征图的深度，从而保持了信息的承载能力\n",
    "class VGG16(Model):\n",
    "    def __ini__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        self.c1 = Conv2D(filters=64,kernel_size=(3,3),padding='same')\n",
    "        self.b1 = BatchNormalization()\n",
    "        self.a1 = Activation('relu')\n",
    "        \n",
    "        self.c2 = Conv2D(filters=64,kernel_size=(3,3),padding='same')\n",
    "        self.b2 = BatchNormalization()\n",
    "        self.a2 = Activation('relu')\n",
    "        self.p2 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "        self.d2 = Dropout(0.2)\n",
    "        \n",
    "        self.c3 = Conv2D(filters=128,kernel_size=(3,3),padding='same')\n",
    "        self.b3 = BatchNormalization()\n",
    "        self.a3 = Activation('relu')\n",
    "        \n",
    "        self.c4 = Conv2D(filters=128,kernel_size=(3,3),padding='same')\n",
    "        self.b4 = BatchNormalization()\n",
    "        self.a4 = Activation('relu')\n",
    "        self.p4 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "        self.d4 = Dropout(0.2)\n",
    "        \n",
    "        self.c5 = Conv2D(filters=256,kernel_size=(3,3),padding='same')\n",
    "        self.b5 = BatchNormalization()\n",
    "        self.a5 = Activation('relu')\n",
    "        \n",
    "        self.c6 = Conv2D(filters=256,kernel_size=(3,3),padding='same')\n",
    "        self.b6 = BatchNormalization()\n",
    "        self.a6 = Activation('relu')\n",
    "        \n",
    "        self.c7 = Conv2D(filters=256,kernel_size=(3,3),padding='same')\n",
    "        self.b7 = BatchNormalization()\n",
    "        self.a7 = Activation('relu')\n",
    "        self.p7 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "        self.d7 = Dropout(0.2)\n",
    "        \n",
    "        self.c8 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b8 = BatchNormalization()\n",
    "        self.a8 = Activation('relu')\n",
    "        \n",
    "        self.c9 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b9 = BatchNormalization()\n",
    "        self.a9 = Activation('relu')\n",
    "        \n",
    "        self.c10 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b10 = BatchNormalization()\n",
    "        self.a10 = Activation('relu')\n",
    "        self.p10 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "        self.d10 = Dropout(0.2)\n",
    "        \n",
    "        self.c11 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b11 = BatchNormalization()\n",
    "        self.a11 = Activation('relu')\n",
    "        \n",
    "        self.c12 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b12 = BatchNormalization()\n",
    "        self.a12 = Activation('relu')\n",
    "        \n",
    "        self.c13 = Conv2D(filters=512,kernel_size=(3,3),padding='same')\n",
    "        self.b13 = BatchNormalization()\n",
    "        self.a13 = Activation('relu')\n",
    "        self.p13 = MaxPool2D(pool_size=(2,2),strides=2,padding='same')\n",
    "        self.d13 = Dropout(0.2)\n",
    "        \n",
    "        self.flatten = Faltten()\n",
    "        self.f14 = Dense(filters=512,activation='relu')\n",
    "        self.d14 = Dropout(0.2)\n",
    "        \n",
    "        self.f15 = Dense(filters=512,activation='relu')\n",
    "        self.d15 = Dropout(0.2)\n",
    "        \n",
    "        self.f16 = Dense(filters=10,activation='softmax')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c566ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionNet核心：inception结构块\n",
    "# 该结构块由四部分祖成，(1*1的卷积核)(1*1叠加3*3卷积核)(1*1叠加5*5卷积核),(3*3pool叠加1*1卷积核)\n",
    "# 两个inceptionz组合成一个block\n",
    "# 同一层网络使用不同尺寸的卷积核，可以提取不同尺寸的特征，提升了模型的感知力，使用了批标准化，缓解梯度消失，\n",
    "class ConvBNRelu(Model):\n",
    "    #先定义好一个卷积核\n",
    "    def __init__(self,ch,kernels=3,strides=1,padding='same'):\n",
    "        super(ConvBNRelu,self).__init__()\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            Conv2D(ch,kernels=kernels,strides=strides,padding = padding),\n",
    "            BatchNornalization(),\n",
    "            Activation('relu')\n",
    "        ])\n",
    "    def call(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "#搭建inception结构快\n",
    "class InceptionBlk(Model):\n",
    "    def __int__(self,ch,strides=1):\n",
    "        super(InceptionBlk,self).__init__()\n",
    "        self.strides = strides\n",
    "        self.c1 = ConvBNRelu(ch,kernels=1,strides=strides)\n",
    "        self.c2_1 = ConvBNRelu(ch,kernels=1,srides=strides)\n",
    "        self.c2_2 = ConvBNRelu(ch,kernels=3,strides=1)\n",
    "        self.c3_1 = ConvBNRelu(ch,kernels=1,srides=strides)\n",
    "        self.c3_2 = ConvBNRelu(ch,kernels=5,strides=1)\n",
    "        self.c4_1 = MaxPool2D(3,srides=1,padding='same')\n",
    "        self.c4_2 = ConvBNRelu(ch,kernels=1,strides=strides)\n",
    "    def call(self,x):\n",
    "        x1 = self.c1(x)\n",
    "        x2_1 = self.c2_1(x)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x3_1 = self.c3_1(x)\n",
    "        x3_2 = self.c3_2(x3_1)\n",
    "        x4_1 = self.c4_1(x)\n",
    "        x4_2 = self.c4_2(x4_1)\n",
    "        x = tf.concat([x1,x2_2,x3_2,x4_2],axis = 3)\n",
    "        return x\n",
    "    \n",
    "#搭建InceptionNet    \n",
    "class Inception10(Model):\n",
    "    def __init__(self,num_blacks,num_classes,init_ch=16,**kwargs):\n",
    "        #init_ch 默认输出深度是16\n",
    "        #num_classes  最后输出的种类数量\n",
    "        #num_bloack 模型的block块数，一块等于两个inception\n",
    "        super(InceptionNet,self).__init__(**kwargs)\n",
    "        self.in_channels = init_ch\n",
    "        self.out_channels = init_ch\n",
    "        self.num_blocks = num_blocks\n",
    "        self.init_ch = init_ch\n",
    "        self.c1 = ConvBNRule(init_ch)\n",
    "        self.blocks = tf.keras.models.Sequencial()\n",
    "        for block_id in range(num_blocks):\n",
    "            for layers_id in range(2):\n",
    "                if layers_id == 0:\n",
    "                    blocks = InceptionBlk(self.out_channels,strides=2)\n",
    "                else:\n",
    "                    blocks = InceptionBlk(self.out_channels,strides=1)\n",
    "                self.blocks.add(block)\n",
    "            # 由于上面strides=2导致输出特征图减半，因此加深输出特征图深度，尽可能保持特征抽取信息的承载量一致\n",
    "            self.out_channels *=2\n",
    "            \n",
    "        self.p1 = GlobalAveragePooling2D()\n",
    "        self.f1 = Dense(num_classes,activation='seftmax')\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.c1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.p1(x)\n",
    "        y = self.f1(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet将前面的特征x直接接到结果f(x)上面，有效解决了神经网络模型堆叠导致的模型退化。使得神经网络可以向更深层级发展。\n",
    "# 分两种情况：f(x)和x维度相同，直接相加；维度不同先用1*1卷积核操作调整x维度，再和f(x)相加\n",
    "# 提出层间残差跳连，引入前方信息，缓解梯度消失，缓解模型退化，是神经网络层数增加成为可能。\n",
    "class ResnetBlock(Model):\n",
    "    def __init__(self,filters,strides=1,residual_path=False):\n",
    "        super(ResnetBlock,self).__init__()\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "        \n",
    "        self.c1 = Conv2D(filters,(3,3),strides=strides,padding='same',use_bias=False)\n",
    "        self.b1 = BatchNormalization()\n",
    "        self.a1 = Activation('relu')\n",
    "        \n",
    "        self.c2 = Conv2D(filters,(3,3),strides=1,padding='same',use_bias=False)\n",
    "        self.b2 = BatchNormalization()\n",
    "        \n",
    "        if residual_path :\n",
    "            self.down_c1 = Conv2D(filters,(1,1),strides=strides,padding='same',use_bias=False)\n",
    "            self.down_b1 = BatchNormalization()\n",
    "            \n",
    "        self.a2 = Activation('relu')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        residual = inputs\n",
    "        x = self.c1(inputs)\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        \n",
    "        x = self.c2(x)\n",
    "        y = self.b2(x)\n",
    "        if self.residual_path:\n",
    "            residual = self.down_c1(inputs)\n",
    "            residual = self.down_b1(residual)\n",
    "            \n",
    "        out = self.a2(y+residual)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class ResNet18(Model):\n",
    "    def __init__(self,block_list,initial_filters=64):#block_list表示每个块有几个卷积层\n",
    "        super(ResNet18,self).__init__()\n",
    "        self.numblock = len(block_list)\n",
    "        self.out_filters = initial_filters\n",
    "        self.c1 = Conv2D(self.out_filters,(3,3),strides=1,padding='same',use_bias=False,\n",
    "                        kernal_initializer='he_normal')\n",
    "        self.b1 = BatchNormalization()\n",
    "        self.a1 = Activation('relu')\n",
    "        self.bloacks = tf.keras.models.Sequential()\n",
    "        \n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "                if block_id != 0 and layer_id == 0:   #对除了第一个block以外的每一个block输入进行下采样\n",
    "                    block = ResnetBlock(self.out_filters,strides=2,residual_path=True)\n",
    "                else:\n",
    "                    block = ResnetBlock(self.out_filters,residual+path = False)\n",
    "                self.blocks.add(block)\n",
    "            self.filters *= 2\n",
    "        self.p1 = tf.keras.layers.GlobalAveragePooling()\n",
    "        self.f1 = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = self.c1(inputs)\n",
    "        x = self.b1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.p1(x)\n",
    "        y = self.f1(x)\n",
    "        return y\n",
    "\n",
    "model = ResNet18([2,2,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e8fd7",
   "metadata": {},
   "source": [
    "# 循环神经网络\n",
    "\n",
    "    循环神经网络\n",
    "        循环核\n",
    "        循环核时间步展开\n",
    "        循环计算层\n",
    "        tf描述循环计算过程\n",
    "        循环计算过程\n",
    "    实践:\n",
    "        字母预测\n",
    "        one_hot\n",
    "        embedding\n",
    "    实践：\n",
    "        股票预测\n",
    "        RNN\n",
    "        LSTM\n",
    "        GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77045531",
   "metadata": {},
   "source": [
    "## 循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e244150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环核：通过不同时刻的参数共享，实现对实践序列信息的提取，\n",
    "# yt = softmax(ht*why + by)\n",
    "# ht = tanh(xt*wxh + h(t-1)*whh + bh)   这就是记忆体，记忆体个数自己定，剩下的参数的维度也就确定。\n",
    "# 前向传播时记忆体内存储的状态信息ht，在每个时刻都被刷新，三个参数矩阵wxh,whh,why自始至终都不变，\n",
    "# 反向传播时，三个参数矩阵被梯度下降更新\n",
    "\n",
    "# 循环神经网络：借助循环神经核提取时间特征后送入全连接网络，\n",
    "\n",
    "# 每个循环核构成一层循环计算层，循环计算层的层数向着输出方向增长。\n",
    "\n",
    "tf,keras.layers.SimpleRNN(记忆体个数，activation='激活函数'默认tanh，\n",
    "                         return_sequences=是否每个时刻输出ht到下一层)\n",
    "# return_sequences=True  表示各时间步输出ht  False表示仅最后的时间步输出ht（默认），\n",
    "# 一般最后一层的循环核用False,中间的层循环核用True,\n",
    "\n",
    "# 进入RNN训练集的维度：\n",
    "# [送入样本数，循环核时间展开步长，每个时间步驶入特征的个数]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661eed3",
   "metadata": {},
   "source": [
    "## 字母预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ce5c9",
   "metadata": {},
   "source": [
    "### one_hot实现字母预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "658b6ec9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5704 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5513 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5325 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5141 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4961 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4785 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4613 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4445 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4280 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4119 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3962 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3808 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.3657 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3509 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3364 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3220 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 993us/step - loss: 1.3079 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2939 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2800 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.2662 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2526 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2389 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2253 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2117 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1982 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1846 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1709 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1573 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1435 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1297 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1159 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1019 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0879 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0739 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0597 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0455 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0312 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0169 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0025 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9881 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9737 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.9592 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9447 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9301 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.9156 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.9010 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8865 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8719 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8573 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8427 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8281 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8135 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7989 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7843 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7697 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7552 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7406 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7261 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7117 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6973 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6829 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6686 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6544 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6403 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6264 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6125 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5988 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5852 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5718 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5586 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5455 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5327 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5201 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5077 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4955 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4835 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4718 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4604 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4492 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4383 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4276 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4172 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4070 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3972 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3875 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3782 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3691 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3603 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3517 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.3434 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3353 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3275 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3200 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3126 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3055 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2986 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2919 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2855 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2792 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2732 - sparse_categorical_accuracy: 1.0000\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_7 (SimpleRNN)     (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 47\n",
      "Trainable params: 47\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 字母预测：输入a预测b,输入b预测c,输入c预测d,输入D预测E，输入E预测a\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = 'abcde'\n",
    "w2id = {'a':0, 'b':1, 'c':2, 'd':3, 'e':4}\n",
    "id2onehot = {0:[1.,0.,0.,0.,0.],1:[0.,1.,0.,0.,0.],2:[0.,0.,1.,0.,0.],3:[0.,0.,0.,1.,0.],4:[0.,0.,0.,0.,1.]}\n",
    "\n",
    "x_train = [id2onehot[w2id['a']],id2onehot[w2id['b']],id2onehot[w2id['c']],id2onehot[w2id['d']],id2onehot[w2id['e']]]\n",
    "y_train = [w2id['b'],w2id['c'],w2id['d'],w2id['e'],w2id['a']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train,(len(x_train),1,5))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(3),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "             metrics = ['sparse_categorical_accuracy'])\n",
    "model.fit(x_train,y_train,batch_size = 32,epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "489f6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input the number of alphabet:5\n",
      "input the test alphabet:a\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 1, 5) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "a->b\n",
      "input the test alphabet:b\n",
      "b->c\n",
      "input the test alphabet:c\n",
      "c->d\n",
      "input the test alphabet:d\n",
      "d->e\n",
      "input the test alphabet:e\n",
      "e->a\n"
     ]
    }
   ],
   "source": [
    "# 效果展示：\n",
    "prenum = int(input('input the number of alphabet:'))\n",
    "for i in range(prenum):\n",
    "    alphabet1 = input('input the test alphabet:')\n",
    "    alphabet = [id2onehot[w2id[alphabet1]]]\n",
    "    alphabet = np.reshape(alphabet,(1,1,5))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result,axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f117a891",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 992us/step - loss: 1.4380 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4127 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3877 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3631 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3389 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3152 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2920 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2692 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2469 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2251 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2037 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1827 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1621 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1418 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1218 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1022 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0827 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0636 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.0446 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0259 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0074 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9892 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9712 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9534 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9359 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.9187 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9017 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8850 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8686 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8525 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8368 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8213 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8061 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7913 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7767 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7625 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7485 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7348 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7213 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7081 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6952 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6824 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6699 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6576 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6454 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6334 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6216 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6099 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5984 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5869 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5756 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5643 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5531 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5308 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5198 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5088 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4979 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4871 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4764 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4658 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4554 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4450 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4349 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4249 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4150 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4054 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3960 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3867 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3776 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3688 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3602 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.3517 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3435 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3355 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3277 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3202 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3128 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3056 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2987 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2920 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2854 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2791 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2730 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2670 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2613 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2557 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2503 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2451 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2400 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2351 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2303 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2257 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2213 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2169 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2128 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2087 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2048 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2010 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1973 - sparse_categorical_accuracy: 1.0000\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_8 (SimpleRNN)     (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 47\n",
      "Trainable params: 47\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 字母预测：循环核按照时间步展开，多个字母预测下一个字母\n",
    "# 输入abcd输出e，输入bcde输出a,输入cdea输出b,输入deab输出c\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = 'abcde'\n",
    "w2id = {'a':0, 'b':1, 'c':2, 'd':3, 'e':4}\n",
    "id2onehot = {0:[1.,0.,0.,0.,0.],1:[0.,1.,0.,0.,0.],2:[0.,0.,1.,0.,0.],3:[0.,0.,0.,1.,0.],4:[0.,0.,0.,0.,1.]}\n",
    "\n",
    "x_train = [[id2onehot[w2id['a']],id2onehot[w2id['b']],id2onehot[w2id['c']],id2onehot[w2id['d']]],\n",
    "           [id2onehot[w2id['b']],id2onehot[w2id['c']],id2onehot[w2id['d']],id2onehot[w2id['e']]],\n",
    "           [id2onehot[w2id['c']],id2onehot[w2id['d']],id2onehot[w2id['e']],id2onehot[w2id['a']]],\n",
    "           [id2onehot[w2id['d']],id2onehot[w2id['e']],id2onehot[w2id['a']],id2onehot[w2id['b']]],\n",
    "           [id2onehot[w2id['e']],id2onehot[w2id['a']],id2onehot[w2id['b']],id2onehot[w2id['c']]]]\n",
    "y_train = [w2id['e'],w2id['a'],w2id['b'],w2id['c'],w2id['d']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train,(len(x_train),4,5))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(3),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "             metrics = ['sparse_categorical_accuracy'])\n",
    "model.fit(x_train,y_train,batch_size = 32,epochs=100)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c87f932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input the number of alphabet:3\n",
      "input the test alphabet:abcd\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 4, 5) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "abcd->e\n",
      "input the test alphabet:bcde\n",
      "bcde->a\n",
      "input the test alphabet:eabc\n",
      "eabc->d\n"
     ]
    }
   ],
   "source": [
    "# 效果展示：\n",
    "prenum = int(input('input the number of alphabet:'))\n",
    "for i in range(prenum):\n",
    "    alphabet1 = input('input the test alphabet:')\n",
    "    alphabet = [id2onehot[w2id[a]] for a in alphabet1]\n",
    "    alphabet = np.reshape(alphabet,(1,4,5))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result,axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e3c83a",
   "metadata": {},
   "source": [
    "### 独热编码和embedding：\n",
    "\n",
    "    独热码：数据量大过于稀疏，映射之间是独立的，没有表现出关联性，和词汇量的位宽一致，词汇量过大时会非常浪费资源。\n",
    "    embedding:是一种单词编码方式，用低位实现了编码，这种编码通过神经网络训练优化，能表达出单词的相关性\n",
    "\n",
    "\n",
    "    tf.keras.layers.Embedding(词汇表大小，编码维度)，编码维度就是用几个数字表示单词,例如1-1001数字用三维数字表示：Embedding(100,3)\n",
    "    进入embedding时，训练集的维度：[送入样本数，循环核时间步展开数]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "902d6ba5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6053 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5999 - sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5941 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5880 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5816 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5747 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5672 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5591 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5505 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5413 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5315 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5211 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5100 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4983 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4860 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4730 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4594 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4452 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4303 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4148 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3987 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3820 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3647 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3469 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3285 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3097 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2904 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2707 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2506 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2303 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2097 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1889 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1680 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1470 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1260 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1051 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0842 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0635 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0429 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0225 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0024 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9825 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9628 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9434 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9243 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9054 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8868 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8684 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8502 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8322 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8144 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7967 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7791 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7617 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7443 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7270 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7097 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6925 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6754 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6584 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6415 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6247 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6080 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5915 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5751 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5589 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5429 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5271 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5116 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4962 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4812 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4664 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4519 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4377 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4239 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4103 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3971 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3842 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3716 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3594 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3476 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3362 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3251 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3144 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3041 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2941 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2846 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2754 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2666 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2581 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2500 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2422 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2348 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2276 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2208 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2142 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2079 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2019 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1961 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1905 - sparse_categorical_accuracy: 1.0000\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 2)           10        \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# embedding代替one_hot实现字母预测：输入a预测b,输入b预测c,输入c预测d,输入D预测E，输入E预测a\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = 'abcde'\n",
    "w2id = {'a':0, 'b':1, 'c':2, 'd':3, 'e':4}\n",
    "id2onehot = {0:[1.,0.,0.,0.,0.],1:[0.,1.,0.,0.,0.],2:[0.,0.,1.,0.,0.],3:[0.,0.,0.,1.,0.],4:[0.,0.,0.,0.,1.]}\n",
    "\n",
    "# 训练集不同\n",
    "x_train = [w2id['a'],w2id['b'],w2id['c'],w2id['d'],w2id['e']]\n",
    "y_train = [w2id['b'],w2id['c'],w2id['d'],w2id['e'],w2id['a']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "#训练集reshape不同\n",
    "x_train = np.reshape(x_train,(len(x_train),1))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(5,2),  #结构不同\n",
    "    SimpleRNN(3),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "             metrics = ['sparse_categorical_accuracy'])\n",
    "model.fit(x_train,y_train,batch_size = 32,epochs=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "872fae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input the number of alphabet:3\n",
      "input the test alphabet:c\n",
      "c->d\n",
      "input the test alphabet:d\n",
      "d->e\n",
      "input the test alphabet:e\n",
      "e->a\n"
     ]
    }
   ],
   "source": [
    "# 预测实例\n",
    "# 效果展示：\n",
    "prenum = int(input('input the number of alphabet:'))\n",
    "for i in range(prenum):\n",
    "    alphabet1 = input('input the test alphabet:')\n",
    "    alphabet = [w2id[alphabet1]]\n",
    "    alphabet = np.reshape(alphabet,(1,1))\n",
    "    result = model.predict([alphabet])\n",
    "    pred = tf.argmax(result,axis=1)\n",
    "    pred = int(pred)\n",
    "    tf.print(alphabet1 + '->' + input_word[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23b0f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6143 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6090 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6030 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5971 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5907 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5832 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5748 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5655 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5551 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5433 - sparse_categorical_accuracy: 0.2000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5302 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5157 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5000 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4830 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4647 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4452 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4247 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4034 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3814 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3588 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3357 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3123 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2888 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2651 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2415 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2178 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1940 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1702 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1462 - sparse_categorical_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1221 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0979 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0736 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0493 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0252 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0017 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9792 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9578 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9372 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9172 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8975 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8782 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8591 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8403 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8216 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8033 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7856 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7686 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7520 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7360 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7205 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7056 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6911 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6771 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6635 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6504 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6377 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6256 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6140 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6029 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5921 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5818 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5718 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5533 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5446 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5362 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5281 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5203 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5127 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5054 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4983 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4913 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4845 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4778 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4713 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4649 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4586 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4525 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4465 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4406 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4348 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4292 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4237 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4182 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4128 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4075 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4023 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3970 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3919 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3867 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3816 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3764 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3713 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3662 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3611 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3559 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3508 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3457 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3406 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3356 - sparse_categorical_accuracy: 1.0000\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 2)           10        \n",
      "_________________________________________________________________\n",
      "simple_rnn_10 (SimpleRNN)    (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 字母预测：循环核按照时间步展开，多个字母预测下一个字母\n",
    "# 输入abcd输出e，输入bcde输出a,输入cdea输出b,输入deab输出c\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN,Dense,Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "input_word = 'abcde'\n",
    "w2id = {'a':0, 'b':1, 'c':2, 'd':3, 'e':4}\n",
    "id2onehot = {0:[1.,0.,0.,0.,0.],1:[0.,1.,0.,0.,0.],2:[0.,0.,1.,0.,0.],3:[0.,0.,0.,1.,0.],4:[0.,0.,0.,0.,1.]}\n",
    "\n",
    "x_train = [[w2id['a'],w2id['b'],w2id['c'],w2id['d']],\n",
    "           [w2id['b'],w2id['c'],w2id['d'],w2id['e']],\n",
    "           [w2id['c'],w2id['d'],w2id['e'],w2id['a']],\n",
    "           [w2id['d'],w2id['e'],w2id['a'],w2id['b']],\n",
    "           [w2id['e'],w2id['a'],w2id['b'],w2id['c']]]\n",
    "y_train = [w2id['e'],w2id['a'],w2id['b'],w2id['c'],w2id['d']]\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train,(len(x_train),4))\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(5,2),\n",
    "    SimpleRNN(3),\n",
    "    Dense(5,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "             metrics = ['sparse_categorical_accuracy'])\n",
    "model.fit(x_train,y_train,batch_size = 32,epochs=100)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23e49f",
   "metadata": {},
   "source": [
    "## 股票预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c41a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "import matplotlib.pyplot as plt\n",
    "df1 = ts.get_k_data('600519',ktype = 'D',start='2010-04-26',end = '2020-04-26')\n",
    "datapath1 = './SH600519.csv'\n",
    "df1.to_csv(datapath1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5935b",
   "metadata": {},
   "source": [
    "### RNN股票预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c927d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 3s 100ms/step - loss: 0.1192 - val_loss: 0.0437\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0270 - val_loss: 0.0040\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0158 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 3s 84ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 3s 91ms/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0073 - val_loss: 0.0178\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0049 - val_loss: 0.0108\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 3s 90ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0039 - val_loss: 0.0191\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 3s 88ms/step - loss: 0.0035 - val_loss: 0.0073\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 3s 103ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 3s 85ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 3s 87ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 3s 96ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 3s 95ms/step - loss: 0.0025 - val_loss: 0.0056\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 3s 97ms/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 3s 92ms/step - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 3s 86ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 3s 83ms/step - loss: 0.0021 - val_loss: 0.0095\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0019 - val_loss: 0.0059\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0018 - val_loss: 0.0092\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0017 - val_loss: 0.0132\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0014 - val_loss: 0.0065\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0014 - val_loss: 0.0057\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 3s 78ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 3s 81ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 3s 82ms/step - loss: 0.0013 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 3s 79ms/step - loss: 0.0013 - val_loss: 9.5025e-04\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0012 - val_loss: 0.0041\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 3s 80ms/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 60, 80)            6560      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60, 80)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 100)               18100     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 24,761\n",
      "Trainable params: 24,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense,SimpleRNN\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')\n",
    "training_set = maotai.iloc[0:2426-300,2:3].values\n",
    "test_set = maotai.iloc[2426-300:,2:3].values\n",
    "\n",
    "#归一化\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "test_set = sc.transform(test_set)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "# 训练集处理\n",
    "for i in range(60,len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "    \n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train = np.reshape(x_train,(len(x_train),60,1))\n",
    "\n",
    "#测试集处理\n",
    "for i in range(60,len(test_set)):\n",
    "    x_test.append(test_set[i-60:i,0])\n",
    "    y_test.append(test_set[i,0])\n",
    "\n",
    "x_test,y_test = np.array(x_test),np.array(y_test)\n",
    "x_test = np.reshape(x_test,(len(x_test),60,1))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(80,return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "             loss = 'mean_squared_error')\n",
    "\n",
    "history = model.fit(x_train,y_train,batch_size = 64,epochs=50,validation_data=(x_test,y_test),validation_freq=1)\n",
    "model.summary()\n",
    "\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "plt.plot(real_stock_price,color='red',label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price,color='blue',label='Predicted MaoTai Stock Price')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(predicted_stock_price,real_stock_price)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price,real_stock_price))\n",
    "mae = mean_absolute_error(predicted_stock_price,real_stock_price)\n",
    "print('均方误差：%.6f'%mse)\n",
    "print('均方根误差：%.6f'%rmse)\n",
    "print('平均绝对误差：%.6f'%mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87927ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差：3874.650635\n",
      "均方根误差：62.246692\n",
      "平均绝对误差：57.742753\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(predicted_stock_price,real_stock_price)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price,real_stock_price))\n",
    "mae = mean_absolute_error(predicted_stock_price,real_stock_price)\n",
    "print('均方误差：%.6f'%mse)\n",
    "print('均方根误差：%.6f'%rmse)\n",
    "print('平均绝对误差：%.6f'%mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903094f",
   "metadata": {},
   "source": [
    "### LSTM预测股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fbd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN通过记忆体实现短期记忆进行连续数据预测，但是当连续数据序列变长时，会使展开时间步过长，在反向传播更新参数时，梯度要按照时间步连续相乘，会导致梯度消失，\n",
    "1997年，Hochereiter提出长短期记忆网络LSTM\n",
    "输入门：it = sigma(wi*[ht-1,xt]+bi)\n",
    "遗忘门：ft = sigma(wf*[ht-1,xt]+bf)\n",
    "输出门：ot = sigma(wo*[ht-1,xt]+bo)\n",
    "细胞态（长期记忆）：ct = ft*c(t-1) + it*ct_hat \n",
    "记忆体（短期记忆）：ht = ot*tanh(ct)\n",
    "候选态（归纳出的新知识）：ct_hat = tanh(wc*[ht-1,xt]+bc)\n",
    "\n",
    "听老师讲课，我现在脑袋中的记住的知识是今天ppt第1页到第45页的长期记忆ct，这个长期记忆ct由两部分组成：\n",
    "第一部分是ppt1-44页的内容，也就是上一时刻的长期记忆ct-1，我不可能一字不差的记住全部内容，会不自觉的忘掉一些，所以上一个时刻的长期记忆ct-1要乘以遗忘门ft，ft*ct-1表示留存在我脑中的对过去的记忆；\n",
    "第二部分是：老师现在讲的内容是新知识，是即将存入我脑中的现在的记忆，现在的记忆由两部分组成：\n",
    "    一部分是老师正在讲的45页ppt，是当前时刻的输入xt,\n",
    "    还有一部分是44页ppt的短期记忆留存ht-1，\n",
    "我的脑袋把当前时刻的输入xt和上一时刻的短期记忆ht-1归纳形成即将存入我脑中的现在记忆ct_hat,\n",
    "现在的记忆ct_hat乘以输入门和过去的记忆一同存贮为长期记忆\n",
    "当我把这部分知识讲给我同学时，我不可能一字不拉讲，而是讲过输出门筛选后的内容，这就是记忆体的输出ht\n",
    "\n",
    "当有多层循环网络时，第一层循环网络的输出ht就是第二层循环网络的输入xt,输入第二层网络的是第一层网络提取的精华，\n",
    "可以认为：老师就是第一层循环网络，每一页ppt都是老师从论文中提取的精华，输出给我，\n",
    "作为第二层循环网络的我，接收到的数据是老师长期记忆过tanh激活函数乘以输出门提取的短期记忆ht，\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.layers.LSTM(记忆体个数，return_sequences=是否返回输出) True表示各时间步输出ht,False表示仅最后时间步输出ht(默认)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#只有两处和上一节RNN预测股票不同，导入包和搭建网络\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense,LSTM  #这里和上节不同\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "\n",
    "maotai = pd.read_csv('./SH600519.csv')\n",
    "training_set = maotai.iloc[0:2426-300,2:3].values\n",
    "test_set = maotai.iloc[2426-300:,2:3].values\n",
    "\n",
    "#归一化\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "test_set = sc.transform(test_set)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "# 训练集处理\n",
    "for i in range(60,len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "    \n",
    "np.random.seed(7)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "x_train,y_train = np.array(x_train),np.array(y_train)\n",
    "x_train = np.reshape(x_train,(len(x_train),60,1))\n",
    "\n",
    "#测试集处理\n",
    "for i in range(60,len(test_set)):\n",
    "    x_test.append(test_set[i-60:i,0])\n",
    "    y_test.append(test_set[i,0])\n",
    "\n",
    "x_test,y_test = np.array(x_test),np.array(y_test)\n",
    "x_test = np.reshape(x_test,(len(x_test),60,1))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    LSTM(80,return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1) \n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "             loss = 'mean_squared_error')\n",
    "\n",
    "history = model.fit(x_train,y_train,batch_size = 64,epochs=50,validation_data=(x_test,y_test),validation_freq=1)\n",
    "model.summary()\n",
    "\n",
    "predicted_stock_price = model.predict(x_test)\n",
    "\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "real_stock_price = sc.inverse_transform(test_set[60:])\n",
    "plt.plot(real_stock_price,color='red',label='MaoTai Stock Price')\n",
    "plt.plot(predicted_stock_price,color='blue',label='Predicted MaoTai Stock Price')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(predicted_stock_price,real_stock_price)\n",
    "rmse = math.sqrt(mean_squared_error(predicted_stock_price,real_stock_price))\n",
    "mae = mean_absolute_error(predicted_stock_price,real_stock_price)\n",
    "print('均方误差：%.6f'%mse)\n",
    "print('均方根误差：%.6f'%rmse)\n",
    "print('平均绝对误差：%.6f'%mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfa334",
   "metadata": {},
   "source": [
    "### GRU预测股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fba3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "2014年Cho等优化Lstm提出GRU\n",
    "\n",
    "更新门：zt = sigmoid(wz*[ht-1,xt])\n",
    "重置门：rt = sigmoid(wr*[ht-1,xt])\n",
    "记忆体：ht = (1-zt)*h(t-1) + zt*ht_hat\n",
    "候选隐藏层：ht_hat = yanh(w*[rt*ht-1,xt])\n",
    "\n",
    "\n",
    "tf.keras.layers.GRU(记忆体个数，return_sequences=是否返回输出),一般最后层用False,中间层用True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    GRU(80,return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    GRU(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb215360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "6",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
